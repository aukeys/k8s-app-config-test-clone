apiVersion: apps/v1
kind: StatefulSet
metadata:
  generation: 1
  labels:
    app: es-min-data
    release: es-min-data
  name: es-min-data
  namespace: es-min
spec:
  #表示按照什么顺序管理pod的启停
  #默认为OrderedReady，可以设置为Parallel这样Pod的创建就不必等待，而是会同时创建、同时删除。
  podManagementPolicy: Parallel
  replicas: 1
  #revisionHistoryLimit 项来指定保留多少旧的ReplicaSet。 余下的将在后台被当作垃圾收集。默认的，所有的revision历史就都会被保留。
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: es-min-data
  serviceName: es-min-data-headless
  template:
    metadata:
      labels:
        app: es-min-data
        release: es-min-data
      name: es-min-data
    spec:
      affinity:
        #用于规定pod不可以和哪些pod部署在同一拓扑结构下
        #因为我只有一台机器，所以只能部署1个data容器/节点，如果部署大于1的data容器，只能部署到相同的work-node节点上，违反了pod反亲和性规则。
        podAntiAffinity:
          #目前有两种主要的 node affinity： 
          #requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution。
          #前者表示 pod 必须部署到满足条件的节点上，如果没有满足条件的节点，就不断重试；后者表示优先部署在满足条件的节点上，如果没有满足条件的节点，就忽略这些条件，按照正常逻辑部署。
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - es-min-data
            #在 Kubernetes 1.4 版本中引入了 Pod 间的亲和性和反亲和性。 
            #Pod 间的亲和性和反亲和性允许根据已经在 node 上运行的 pod 的标签 来限制 pod 调度在哪个 node 上，而不是基于 node 上的标签。
            #这些规则的形式是 “如果 X 已经运行一个或多个符合规则 Y 的 pod，那么这个 pod 应该（如果是反亲和性，则是不应该）运行在 X 上”。
            #这里 Y 指具有关联命名空间列表的 LabelSelector（或者关联 “all” 命名空间）；
            #和 node 不同，由于 pod 都是有命名空间的（因此 pod 上的标签都隐式具有命名空间），
            #所以基于 pod 标签的标签选择器（label selector）必须指定命名空间。
            #概念上，X 是一个拓扑域，类似于 node、rack、cloud provider zone 和 cloud provider region 等等。您可以使用 topologyKey 来表示这个 X，topologyKey 是系统用来表示这个拓扑域的 node 标签，
            #K8S 默认支持如下 topology domain。
            #kubernetes.io/hostname
            #failure-domain.beta.kubernetes.io/zone
            #failure-domain.beta.kubernetes.io/region
            #既然 topologyKey 是拓扑域，那 Pod 之间怎样才是属于同一个拓扑域？
            #如果使用 k8s.io/hostname，
            #则表示拓扑域为 Node 范围，那么 k8s.io/hostname 对应的值不一样就是不同的拓扑域。
            #比如 Pod1 在 k8s.io/hostname=node1 的 Node 上，Pod2 在 k8s.io/hostname=node2 的 Node 上，Pod3 在 k8s.io/hostname=node1 的 Node 上，则 Pod2 和 Pod1、Pod3 不在同一个拓扑域，而Pod1 和 Pod3在同一个拓扑域。
            #如果使用 failure-domain.k8s.io/zone ，
            #则表示拓扑域为一个区域。同样，Node 的标签 failure-domain.k8s.io/zone 对应的值不一样也不是同一个拓扑域，
            #比如 Pod1 在 failure-domain.k8s.io/zone=beijing 的 Node 上，Pod2 在 failure-domain.k8s.io/zone=hangzhou 的 Node 上，则 Pod1 和 Pod2 不属于同一个拓扑域。
            topologyKey: kubernetes.io/hostname
      containers:
      - env:
        - name: node.name
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: discovery.zen.ping.unicast.hosts
          value: es-min-master-headless
        - name: cluster.name
          value: es-min
        - name: discovery.zen.minimum_master_nodes
          value: "1"
        - name: network.host
          value: 0.0.0.0
        - name: ES_JAVA_OPTS
          value: -Xmx1g -Xms1g
        - name: node.master
          value: "false"
        - name: node.data
          value: "true"
        - name: node.ingest
          value: "false"
        image: hpy253215039/elasticsearch:6.4.3
        imagePullPolicy: IfNotPresent
        name: elasticsearch
        #要暴露的端口
        ports:
        - containerPort: 9200
          name: http
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        ##Kubelet 使用 readiness probe（就绪探针）来确定容器是否已经就绪可以接受流量。
        #只有当 Pod 中的容器都处于就绪状态时 kubelet 才会认定该 Pod处于就绪状态。该信号的作用是控制哪些 Pod应该作为service的后端。如果 Pod 处于非就绪状态，那么它们将会被从 service 的 load balancer中移除。
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              #!/usr/bin/env bash -e
              # If the node is starting up wait for the cluster to be green
              # Once it has started only check that the node itself is responding
              START_FILE=/tmp/.es_start_file

              http () {
                  local path="${1}"
                  if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                    BASIC_AUTH="-u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                  else
                    BASIC_AUTH=''
                  fi
                  curl -XGET -s -k --fail ${BASIC_AUTH} http://127.0.0.1:9200${path}
              }

              if [ -f "${START_FILE}" ]; then
                  echo 'Elasticsearch is already running, lets check the node is healthy'
                  http "/"
              else
                  echo 'Waiting for elasticsearch cluster to become green'
                  if http "/_cluster/health?wait_for_status=green&timeout=1s" ; then
                      touch ${START_FILE}
                      exit 0
                  else
                      echo 'Cluster is not yet green'
                      exit 1
                  fi
              fi
          #探测成功后，最少连续探测失败多少次才被认定为失败。默认是 3。最小值是 1。
          failureThreshold: 3
          #容器启动后第一次执行探测是需要等待多少秒。
          initialDelaySeconds: 10
          #执行探测的频率。默认是10秒，最小1秒。
          periodSeconds: 10
          #探测失败后，最少连续探测成功多少次才被认定为成功。默认是 1。对于 liveness 必须是 1。最小值是 1。
          successThreshold: 3
          #探测超时时间。默认1秒，最小1秒。
          timeoutSeconds: 5
        #限定资源
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 2Gi
        #为了达到一个相当高水平的实用性，特别是为了积极开发应用，快速调试失败是很重要的。
        #除了一般的日志采集，Kubernetes还能通过查出重大错误原因来加速调试，并在某种程度上通过kubectl或者UI陈列出来。
        #可以指定一个’terminationMessagePath’来让容器写下它的“death rattle“，比如声明失败消息，堆栈跟踪，免责条款等等。默认途径是‘/dev/termination-log’。
        terminationMessagePath: /dev/termination-log
        # 此字段默认为 “File“，这意味着仅从终止消息文件中检索终止消息。 
        # 通过将 terminationMessagePolicy 设置为 “FallbackToLogsOnError“，你就可以告诉 Kubernetes，在容器因错误退出时，
        # 如果终止消息文件为空，则使用容器日志输出的最后一块作为终止消息。 日志输出限制为 2048 字节或 80 行，以较小者为准。
        terminationMessagePolicy: File
        #要使用的数据盘目录，在initContainer中会关联此处目录。
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: es-min-data
      dnsPolicy: ClusterFirst
      #Init 容器支持应用容器的全部字段和特性，包括资源限制、数据卷和安全设置。 然而，Init 容器对资源请求和限制的处理稍有不同，在下面 资源 处有说明。 而且 Init 容器不支持 Readiness Probe，因为它们必须在 Pod 就绪之前运行完成。
      #如果为一个 Pod 指定了多个 Init 容器，那些容器会按顺序一次运行一个。 每个 Init 容器必须运行成功，下一个才能够运行。 当所有的 Init 容器运行完成时，Kubernetes 初始化 Pod 并像平常一样运行应用容器。
      #mysql这里的initContainer是为了保证在POD启动前，PV盘要先行绑定成功。
      initContainers:
      - command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        image: hpy253215039/elasticsearch:6.4.3
        imagePullPolicy: IfNotPresent
        name: configure-sysctl
        resources: {}
        securityContext:
          privileged: true
          procMount: Default
          runAsUser: 0
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      #如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活探针; kubelet 将根据 Pod 的restartPolicy 自动执行正确的操作。
      restartPolicy: Always
      #scheduler 是 kubernetes 的调度器，主要的任务是把定义的 pod 分配到集群的节点上。
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 1000
      #如果您的Pod通常需要超过30秒才能关闭，请确保增加优雅终止宽限期。可以通过在Pod YAML中设置terminationGracePeriodSeconds选项来实现.
      #如果容器在优雅终止宽限期后仍在运行，则会发送SIGKILL信号并强制删除。与此同时，所有的Kubernetes对象也会被清除。
      terminationGracePeriodSeconds: 120
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: es-min-data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
      storageClassName: es-min-data-pv-local
      volumeMode: Filesystem
